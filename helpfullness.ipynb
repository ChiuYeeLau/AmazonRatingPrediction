{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import numpy\n",
    "import urllib\n",
    "import scipy.optimize\n",
    "import random\n",
    "from sklearn.ensemble.forest import DecisionTreeRegressor as tree\n",
    "from textstat.textstat import textstat\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readGz(f):\n",
    "  for l in gzip.open(f):\n",
    "    yield eval(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# /play"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# baseline code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allHelpful = []\n",
    "userHelpful = defaultdict(list)\n",
    "\n",
    "for l in readGz(\"train.json.gz\"):\n",
    "    user,item = l['reviewerID'],l['itemID']\n",
    "    allHelpful.append(l['helpful'])\n",
    "    userHelpful[user].append(l['helpful'])\n",
    "\n",
    "averageRate = sum([x['nHelpful'] for x in allHelpful]) * 1.0 / sum([x['outOf'] for x in allHelpful])\n",
    "userRate = {}\n",
    "for u in userHelpful:\n",
    "    totalU = sum([x['outOf'] for x in userHelpful[u]])\n",
    "    if totalU > 0:\n",
    "        userRate[u] = sum([x['nHelpful'] for x in userHelpful[u]]) * 1.0 / totalU\n",
    "    else:\n",
    "        userRate[u] = averageRate\n",
    "\n",
    "# predictions = open(\"assignment1/predictions_Helpful.txt\", 'w')\n",
    "# for l in open(\"assignment1/pairs_Helpful.txt\"):\n",
    "#     if l.startswith(\"userID\"):\n",
    "#         #header\n",
    "#         predictions.write(l)\n",
    "#         continue\n",
    "#     u,i,outOf = l.strip().split('-')\n",
    "#     outOf = int(outOf)\n",
    "#     if u in userRate:\n",
    "#         predictions.write(u + '-' + i + '-' + str(outOf) + ',' + str(outOf*userRate[u]) + '\\n')\n",
    "#     else:\n",
    "#         predictions.write(u + '-' + i + '-' + str(outOf) + ',' + str(outOf*averageRate) + '\\n')\n",
    "\n",
    "# predictions.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xyvalid = []\n",
    "for i,l in enumerate(readGz(\"train.json.gz\")):\n",
    "    if i <= 900000:\n",
    "        continue\n",
    "    Xyvalid.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.shuffle(Xyvalid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fit data for first 100k points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for i,l in enumerate(readGz(\"train.json.gz\")):\n",
    "    if i >= 900000:\n",
    "        break\n",
    "\n",
    "    user,item,review,rating,helpful,summary = l['reviewerID'],l['itemID'],l['reviewText'],l['rating'],l['helpful'],l['summary']\n",
    "    uTerm = averageRate if user not in userRate else userRate[user]\n",
    "    review = review if review else ''\n",
    "    assert review is not None\n",
    "    \n",
    "    review_wc = textstat.lexicon_count(review)\n",
    "    summary_wc = textstat.lexicon_count(summary)\n",
    "    punct_ratio = 0 if not review_wc else (1.0*sum([c in string.punctuation for c in review]))/review_wc\n",
    "    \n",
    "    X.append([uTerm, rating, review_wc, summary_wc, punct_ratio])\n",
    "    y.append(uTerm if helpful['outOf']==0 or helpful['nHelpful'] == 0 else (helpful['nHelpful']*1.0)/helpful['outOf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xhelp = []\n",
    "for x in X:\n",
    "    x = [x[0], round(x[1]/3.88, 2), x[2], x[3], x[4], x[5]]\n",
    "    Xhelp.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xlinreg = []\n",
    "for x in X:\n",
    "    x.append(1)\n",
    "    Xlinreg.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta,residuals,rank,s = numpy.linalg.lstsq(Xlinreg, y)\n",
    "print theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = tree(min_samples_leaf=17, max_depth=35)\n",
    "model = model.fit(Xhelp,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.053, 0.922, 0.009, 0.008, 0.002, 0.007]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[round(x,3) for x in model.feature_importances_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble.forest import RandomForestRegressor\n",
    "RF = RandomForestRegressor(n_estimators = 5, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.5s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=5, n_jobs=1, oob_score=False, random_state=None,\n",
       "           verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "RF.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "yPred = RF.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.83333333,  0.        ,  0.5       , ...,  0.4       ,\n",
       "        0.66666667,  0.83333333])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valid error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leaf 16\n",
      "0.521449993404\n",
      "leaf 17\n",
      "0.517859380001\n",
      "leaf 18\n",
      "0.517859380001\n",
      "leaf 19\n",
      "0.517859380001\n",
      "leaf 20\n",
      "0.517859380001\n"
     ]
    }
   ],
   "source": [
    "merror = 9999\n",
    "bparams = (None, None)\n",
    "\n",
    "for leaf in range(16, 21, 1):\n",
    "    print 'leaf', leaf\n",
    "    \n",
    "    for depth in range(35, 105, 15):\n",
    "        model = tree(min_samples_leaf=leaf, max_depth=depth)\n",
    "        model = model.fit(Xhelp,y)\n",
    "\n",
    "        errors = 0\n",
    "        for i,l in enumerate(Xyvalid[:10000]):\n",
    "#             if i >= 10000:\n",
    "#                 break\n",
    "#             if i%1000 == 0:\n",
    "#                 print i\n",
    "\n",
    "            user,item,review,rating,helpful,summary= l['reviewerID'],l['itemID'],l['reviewText'],l['rating'],l['helpful'],l['summary']\n",
    "            uTerm = averageRate if user not in userRate else userRate[user]\n",
    "            review = review if review else ''\n",
    "            assert review is not None\n",
    "\n",
    "            review_wc = textstat.lexicon_count(review)\n",
    "            summary_wc = textstat.lexicon_count(summary)\n",
    "            punct_ratio = 0 if not review_wc else (1.0*sum([c in string.punctuation for c in review]))/review_wc\n",
    "\n",
    "            x = [uTerm, helpful['outOf'], rating, review_wc, summary_wc, punct_ratio]\n",
    "\n",
    "            pred = model.predict(x)\n",
    "            pred = l['helpful']['outOf'] * pred\n",
    "\n",
    "            errors += abs(pred-l['helpful']['nHelpful'])\n",
    "\n",
    "\n",
    "        rate = float(errors)/10000\n",
    "        if rate < merror:\n",
    "            merror = rate\n",
    "            bparams = (leaf, depth)\n",
    "        \n",
    "    print merror\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 35)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "errors = 0\n",
    "for i,l in enumerate(Xyvalid):\n",
    "    if i >= 10000:\n",
    "        break\n",
    "    if i%1000 == 0:\n",
    "        print i\n",
    "    \n",
    "    user,item,review,rating,helpful,summary= l['reviewerID'],l['itemID'],l['reviewText'],l['rating'],l['helpful'],l['summary']\n",
    "    uTerm = averageRate if user not in userRate else userRate[user]\n",
    "    review = review if review else ''\n",
    "    assert review is not None\n",
    "    \n",
    "    review_wc = textstat.lexicon_count(review)\n",
    "    summary_wc = textstat.lexicon_count(summary)\n",
    "    punct_ratio = 0 if not review_wc else (1.0*sum([c in string.punctuation for c in review]))/review_wc\n",
    "    \n",
    "    x = [uTerm, helpful['outOf'], rating, review_wc, summary_wc, punct_ratio]\n",
    "    \n",
    "    pred = model.predict(x)\n",
    "    pred = l['helpful']['outOf'] * pred\n",
    "    \n",
    "    errors += abs(pred-l['helpful']['nHelpful'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "0.492998554891\n"
     ]
    }
   ],
   "source": [
    "errors = 0\n",
    "for i,l in enumerate(readGz(\"assignment1/train.json.gz\")):\n",
    "    if i >= 10000:\n",
    "        break\n",
    "    if i%1000 == 0:\n",
    "        print i\n",
    "    \n",
    "    user,item,review,rating,helpful,summary= l['reviewerID'],l['itemID'],l['reviewText'],l['rating'],l['helpful'],l['summary']\n",
    "    uTerm = averageRate if user not in userRate else userRate[user]\n",
    "    review = review if review else ''\n",
    "    assert review is not None\n",
    "    \n",
    "    review_wc = textstat.lexicon_count(review)\n",
    "    summary_wc = textstat.lexicon_count(summary)\n",
    "    punct_ratio = 0 if not review_wc else (1.0*sum([c in string.punctuation for c in review]))/review_wc\n",
    "    \n",
    "    x = [uTerm, helpful['outOf'], rating, review_wc, summary_wc, punct_ratio]\n",
    "    \n",
    "    pred = model.predict(x)\n",
    "    pred = l['helpful']['outOf'] * pred\n",
    "    \n",
    "    errors += abs(pred-l['helpful']['nHelpful'])\n",
    "\n",
    "\n",
    "print float(errors)/10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pairs = open(\"assignment1/pairs_Helpful.txt\").readlines()\n",
    "predictions = open(\"assignment1/predictions_Helpful.txt\", 'w')\n",
    "predictions.write(pairs[0])\n",
    "\n",
    "for idx, l in enumerate(readGz(\"assignment1/helpful.json.gz\")):\n",
    "    idx += 1\n",
    "    \n",
    "    user,item,review,rating,helpful,summary= l['reviewerID'],l['itemID'],l['reviewText'],l['rating'],l['helpful'],l['summary']\n",
    "    uTerm = averageRate if user not in userRate else userRate[user]\n",
    "    review = review if review else ''\n",
    "    assert review is not None\n",
    "    \n",
    "    review_wc = textstat.lexicon_count(review)\n",
    "    summary_wc = textstat.lexicon_count(summary)\n",
    "    punct_ratio = 0 if not review_wc else (1.0*sum([c in string.punctuation for c in review]))/review_wc\n",
    "    \n",
    "    x = [uTerm, helpful['outOf'], rating, review_wc, summary_wc, punct_ratio]\n",
    "        \n",
    "    prediction = model.predict(x)\n",
    "    \n",
    "    u,i,outOf = pairs[idx].strip().split('-')\n",
    "    outOf = int(outOf)\n",
    "    \n",
    "    predictions.write(u + '-' + i + '-' + str(outOf) + ',' + str(prediction[0]*outOf) + '\\n')\n",
    "    \n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
